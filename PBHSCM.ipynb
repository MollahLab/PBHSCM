{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Min Shi\n",
    "## Last updated: 4/29/2021\n",
    "\n",
    "## Description:\n",
    "The code was created to implement the scoring models to predict peripheral blood hematopoietic stem cell mobilization in allogeneic donors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl import load_workbook\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file = os.path.join('./','path of the input file')\n",
    "dataset = pd.read_csv(file).set_index('Patient ID').rename(columns={'Day 1 CD34 Absolute per uL': 'count',\n",
    "                                                                   'Day 1 CD34/kg (x10^6)':'optional_outcome'})\n",
    "\n",
    "# Take the optional outcome into consideration\n",
    "dataset.loc[(dataset['count'].isna()) & (dataset['optional_outcome'] >= 2.0), 'count'] = 100\n",
    "dataset.loc[(dataset['count'].isna()) & (dataset['optional_outcome'] < 2.0), 'count'] = 10\n",
    "\n",
    "dataset=dataset.drop(['optional_outcome'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing\n",
    "1. Map CD34+ counts to Class 1 (0), Class 2 (1)\n",
    "\n",
    "2. Normalize or scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# remove all rows containing N/A and map samples to respective classes\n",
    "dataset_remove_NaN = dataset.dropna(axis=0, how='any')\n",
    "\n",
    "dataset_remove_NaN.loc[dataset_remove_NaN['count'] < 40, 'count'] = 0\n",
    "# dataset_remove_NaN.loc[(dataset_remove_NaN['count'] >= 20) & (dataset_remove_NaN['count'] < 40), 'count'] = 1\n",
    "# dataset_remove_NaN.loc[dataset_remove_NaN['count'] >= 40, 'count'] = 2\n",
    "dataset_remove_NaN.loc[dataset_remove_NaN['count'] >= 40, 'count'] = 1\n",
    "\n",
    "\n",
    "\n",
    "# dataset_remove_NaN = dataset_remove_NaN[['count','Age','BMI','Sodium','Chloride','BUN','ALT','AST','WBC','RBC','Hgb','Hct', 'Platelet Ct',\n",
    "#                    'MCV','MCH','MCHC','MPV','Neut Abs','Lymphocyte Abs']]\n",
    "\n",
    "# dataset_remove_NaN = dataset_remove_NaN[['count','Age','BMI','WBC','RBC','Hct', 'Platelet Ct',\n",
    "#                    'MCV','MCH']]\n",
    "\n",
    "# dataset_remove_NaN = dataset_remove_NaN[['count','BMI','MCV','MCH']]\n",
    "\n",
    "dataset_remove_NaN['count'] = dataset_remove_NaN['count'].apply(np.int64)\n",
    "labels = list(dataset_remove_NaN['count'])\n",
    "counter = dict((i, labels.count(i)) for i in labels)\n",
    "print('Class distribution:', counter)\n",
    "\n",
    "fig = plt.figure(figsize=(5.4, 4.3))\n",
    "pyplot.xlabel('Distribution of Class 0 (171) and Class 1 (628)', fontsize=14, labelpad=10)\n",
    "pyplot.ylabel('Number of Donors', fontsize=14)\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.xticks([r for r in range(len(counter.keys()))], ['Class 0', 'Class 1', '2'])\n",
    "ax = fig.add_subplot(111)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "pyplot.show()\n",
    "\n",
    "# apply linear normalization\n",
    "df_temp = dataset_remove_NaN.iloc[:,1:]\n",
    "dataset_remove_NaN.iloc[:,1:] = (df_temp - df_temp.min()) / (df_temp.max() - df_temp.min())\n",
    "\n",
    "dataset_remove_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "raw_features = np.array(dataset_remove_NaN.columns)[1:]\n",
    "donor_ids = np.array(dataset_remove_NaN.index)\n",
    "raw_inputs = dataset_remove_NaN.values\n",
    "X = raw_inputs[:,1:]\n",
    "y = raw_inputs[:,0]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "raw_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "raw_features = np.array(dataset_remove_NaN.columns)[1:]\n",
    "raw_inputs = dataset_remove_NaN.values\n",
    "X = raw_inputs[:,1:]\n",
    "y = raw_inputs[:,0]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# counter_train = Counter(y_train)\n",
    "# print('{} samples fot training, class distribution:'.format(len(y_train)), dict(counter_train))\n",
    "\n",
    "# counter_test = Counter(y_test)\n",
    "# print('{} samples fot test, class distribution:'.format(len(y_test)), dict(counter_test))\n",
    "\n",
    "# x_inputs = X_train\n",
    "# y_inputs = y_train\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=50, random_state=0)\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_selected = model.transform(X)\n",
    "feat_num = X_selected.shape[1]\n",
    "\n",
    "indx = sorted(range(len(importances)), key=lambda i: importances[i])[-feat_num:]\n",
    "print(\"{} selected features are :\\n\".format(feat_num), raw_features[indx], importances[indx],'\\n')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\", fontsize=13)\n",
    "plt.bar(range(X_selected.shape[1]), importances[indx],\n",
    "        color=\"r\", yerr=std[indx], align=\"center\")\n",
    "plt.xticks(range(X_selected.shape[1]), raw_features[indx], rotation=90, fontsize=12)\n",
    "plt.xlim([-1, X_selected.shape[1]])\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-SNE based Visualization of the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the embeddings\n",
    "from sklearn.manifold import TSNE\n",
    "import random\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "label_map = {}\n",
    "\n",
    "# with open(labelsfile) as lr:\n",
    "#     for line in lr:\n",
    "#         params = line.split()\n",
    "#         node_id = params[0]\n",
    "#         labelss = params[1]\n",
    "#         label_map[node_id] = labelss\n",
    "\n",
    "        \n",
    "groups = list(set(y))\n",
    "groups.sort()\n",
    "# print(groups)\n",
    "\n",
    "embeddings = np.array(X)\n",
    "labels = np.array(y)\n",
    "\n",
    "tsne = TSNE(perplexity=20, n_components=2, init='pca', n_iter=2000)\n",
    "low_dim_embs = tsne.fit_transform(embeddings)\n",
    "\n",
    "colors = {\n",
    "'darkorange':'#FF8C00','deepskyblue':'#00BFFF','deeppink':'#FF1493','darkgreen':'#006400',\n",
    "    'dimgray': '#696969','darkmagenta':'#8B008B','darkred':'#8B0000',\n",
    "    'darkgray':'#A9A9A9','darkgoldenrod':'#B8860B','aliceblue':'#F0F8FF', 'darkseagreen':'#8FBC8F',\n",
    "    'bisque':'#FFE4C4','antiquewhite':'#FAEBD7',\n",
    "'aquamarine': '#7FFFD4','azure':'#F0FFFF','beige':'#F5F5DC','black': '#000000',\n",
    "'blanchedalmond':'#FFEBCD','blue':'#0000FF','blueviolet':'#8A2BE2','burlywood':'#DEB887',\n",
    "'cadetblue':'#5F9EA0','chartreuse':'#7FFF00','chocolate':'#D2691E','coral':'#FF7F50',\n",
    "'cornflowerblue':'#6495ED','crimson':'#DC143C',\n",
    "'cyan':'#00FFFF','darkblue':'#00008B','darkcyan':'#008B8B',\n",
    "'darkolivegreen':'#556B2F',\n",
    "'darkorchid':'#9932CC','darksalmon':'#E9967A','darkslateblue':'#483D8B',\n",
    "'darkslategray':'#2F4F4F','darkturquoise':'#00CED1','darkkhaki':'#BDB76B'\n",
    "}\n",
    "labs = ['Class 0', 'Class 1']\n",
    "plt.figure(figsize=(4.5, 4.5))\n",
    "for i, c, label in zip(groups, colors, groups):\n",
    "    plt.scatter(low_dim_embs[labels == i, 0], low_dim_embs[labels == i, 1], c = c, label=labs[int(label)], s =8)\n",
    "    \n",
    "plt.legend(fontsize=11,handletextpad=0.2)\n",
    "plt.xticks(fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Methods to mitigate the class imbalanced problem\n",
    "1. Oversampling\n",
    "\n",
    "2. SMOTE\n",
    "\n",
    "3. Cost-Sensitive Penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 SMOTE (Synthetic Minority Over-sampling Technique) \n",
    "https://arxiv.org/pdf/1106.1813.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "\n",
    "# y_inputs = LabelEncoder().fit_transform(y_inputs)\n",
    "oversample = SMOTE(random_state=42)\n",
    "X_smote, y_smote = oversample.fit_resample(X, y)\n",
    "counter = Counter(y_smote)\n",
    "print('Class distribution:', counter)\n",
    "\n",
    "fig = plt.figure(figsize=(5.4, 4.3))\n",
    "pyplot.xlabel('Distribution of Class 0 (628) and Class 1 (628)', fontsize=14, labelpad=10)\n",
    "pyplot.ylabel('Number of Donors', fontsize=14)\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.xticks([r for r in range(len(counter.keys()))], ['Class 0', 'Class 1', '2'])\n",
    "ax = fig.add_subplot(111)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from collections import Counter\n",
    "\n",
    "# # y_inputs = LabelEncoder().fit_transform(y_inputs)\n",
    "# oversample = SMOTE(random_state=42)\n",
    "# X_smote_selected, y_smote_selected = oversample.fit_resample(X_selected, y)\n",
    "# counter = Counter(y_smote_selected)\n",
    "# print('Class distribution:', counter)\n",
    "\n",
    "# fig = plt.figure(figsize=(5.4, 4.3))\n",
    "# pyplot.xlabel('Distribution of Class 0 (628) and Class 1 (628)', fontsize=14, labelpad=10)\n",
    "# pyplot.ylabel('Number of Donors', fontsize=14)\n",
    "# pyplot.bar(counter.keys(), counter.values())\n",
    "# pyplot.xticks([r for r in range(len(counter.keys()))], ['Class 0', 'Class 1', '2'])\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_smote, y_smote = X, y\n",
    "# counter = Counter(y_smote)\n",
    "# print('Class distribution:', counter)\n",
    "\n",
    "# fig = plt.figure(figsize=(5.4, 4.3))\n",
    "# pyplot.xlabel('Distribution of Class 1 and Class 2', fontsize=14, labelpad=10)\n",
    "# pyplot.ylabel('Number of Patients', fontsize=14)\n",
    "# pyplot.bar(counter.keys(), counter.values())\n",
    "# pyplot.xticks([r for r in range(len(counter.keys()))], ['0', '1', '2'])\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Build the prediction model\n",
    "1. Decision Tree (DT)  \n",
    "\n",
    "2. Linear Regression (LR) \n",
    "\n",
    "3. Random Forest (RF) \n",
    "\n",
    "4. Feedforward Neural Networks (FNN)\n",
    "\n",
    "5. Support Vector Machine (SVM) \n",
    "\n",
    "6. AdaBoost\n",
    "\n",
    "7. GradientBoosting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0, max_depth=17, criterion='entropy', min_samples_split=4)\n",
    "\n",
    "accs = []\n",
    "confusion_mats = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "scores_id = []\n",
    "scores = []\n",
    "for i, (train, test) in enumerate(cv.split(X_smote_selected, y_smote_selected)):\n",
    "    clf.fit(X_smote_selected[train], y_smote_selected[train])\n",
    "    y_pred = clf.predict(X_smote_selected[test])\n",
    "    y_test = y_smote_selected[test]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    scores_id.append(test)\n",
    "    scores.append(clf.predict_proba(X_smote_selected[test]))\n",
    "    \n",
    "\n",
    "# save prediction score\n",
    "scores_id = np.concatenate(scores_id, axis=0) \n",
    "scores = np.concatenate(scores, axis=0) \n",
    "map_ids = []\n",
    "for i in range(len(donor_ids)):\n",
    "    map_ids.append(np.where(scores_id==i)[0][0])\n",
    "map_scores = scores[map_ids]\n",
    "y_predict = np.argmax(map_scores, axis=1) \n",
    "    \n",
    "accuracy_dt = accuracy_score(y, y_predict)\n",
    "confusion_mat_dt = confusion_matrix(y, y_predict)\n",
    "f1_dt = f1_score(y, y_predict)    \n",
    "auc_dt = roc_auc_score(y, y_predict)\n",
    "fpr_dt,tpr_dt,_ = roc_curve(y, y_predict)\n",
    "\n",
    "\n",
    "# print(scores[9])\n",
    "\n",
    "# clf.fit(X_smote, y_smote)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print('y_true', y_test)\n",
    "# print('y_predict', y_pred)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Pred Accuray=%.3f'% accuracy_dt)\n",
    "\n",
    "\n",
    "# confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('confusion_mat:\\n', confusion_mat_dt)\n",
    "\n",
    "# f1_dt, auc_dt = f1_score(y_test, y_pred), roc_auc_score(y_test,y_pred)\n",
    "print('F1=%.3f Auc=%.3f' % (f1_dt, auc_dt))\n",
    "# fpr_dt, tpr_dt, _ = roc_curve(y_test, y_pred)\n",
    "pyplot.plot(fpr_dt, tpr_dt, marker='.', label='Decision Tree')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "# clf.predict_proba(X_test)\n",
    "\n",
    "# save prediction score\n",
    "# scores_id = np.concatenate(scores_id, axis=0) \n",
    "# scores = np.concatenate(scores, axis=0) \n",
    "# map_ids = []\n",
    "# for i in range(len(donor_ids)):\n",
    "#     map_ids.append(np.where(scores_id==i)[0][0])\n",
    "# map_scores = scores[map_ids]\n",
    "\n",
    "df_dt = pd.DataFrame(map_scores, index=donor_ids,  columns=['class 0', 'Class 1'])\n",
    "\n",
    "writer = pd.ExcelWriter(\"model_prediction_scores_new.xlsx\")\n",
    "df_dt.to_excel(writer, 'Decision Tree')\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000, multi_class='ovr')\n",
    "\n",
    "accs = []\n",
    "confusion_mats = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "scores_id = []\n",
    "scores = []\n",
    "for i, (train, test) in enumerate(cv.split(X_smote_selected, y_smote_selected)):\n",
    "    clf.fit(X_smote_selected[train], y_smote_selected[train])\n",
    "    y_pred = clf.predict(X_smote_selected[test])\n",
    "    y_test = y_smote_selected[test]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    scores_id.append(test)\n",
    "    scores.append(clf.predict_proba(X_smote_selected[test]))\n",
    "    \n",
    "    \n",
    "# save prediction score\n",
    "scores_id = np.concatenate(scores_id, axis=0) \n",
    "scores = np.concatenate(scores, axis=0) \n",
    "map_ids = []\n",
    "for i in range(len(donor_ids)):\n",
    "    map_ids.append(np.where(scores_id==i)[0][0])\n",
    "map_scores = scores[map_ids]\n",
    "y_predict = np.argmax(map_scores, axis=1) \n",
    "    \n",
    "accuracy_lr = accuracy_score(y, y_predict)\n",
    "confusion_mat_lr = confusion_matrix(y, y_predict)\n",
    "f1_lr = f1_score(y, y_predict)    \n",
    "auc_lr = roc_auc_score(y, y_predict)\n",
    "fpr_lr,tpr_lr,_ = roc_curve(y, y_predict)\n",
    "\n",
    "# clf.fit(X_smote, y_smote)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print('y_true', y_test)\n",
    "# print('y_predict', y_pred)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Prediction accuray:', accuracy_lr)\n",
    "\n",
    "# confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('confusion_mat:\\n', confusion_mat_lr)\n",
    "\n",
    "# f1_lr, auc_lr = f1_score(y_test, y_pred), roc_auc_score(y_test,y_pred)\n",
    "print('F1=%.3f Auc=%.3f' % (f1_lr, auc_lr))\n",
    "# fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred)\n",
    "pyplot.plot(fpr_lr, tpr_lr, marker='.', label='Linear Regression')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "# save prediction score\n",
    "# scores_id = np.concatenate(scores_id, axis=0) \n",
    "# scores = np.concatenate(scores, axis=0) \n",
    "# map_ids = []\n",
    "# for i in range(len(donor_ids)):\n",
    "#     map_ids.append(np.where(scores_id==i)[0][0])\n",
    "# map_scores = scores[map_ids]\n",
    "\n",
    "df_dt = pd.DataFrame(map_scores, index=donor_ids,  columns=['class 0', 'Class 1'])\n",
    "\n",
    "df_dt.to_excel(writer, 'Linear Regression')\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=18, random_state=0)\n",
    "\n",
    "accs = []\n",
    "confusion_mats = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "scores_id = []\n",
    "scores = []\n",
    "for i, (train, test) in enumerate(cv.split(X_smote, y_smote)):\n",
    "    clf.fit(X_smote[train], y_smote[train])\n",
    "    y_pred = clf.predict(X_smote[test])\n",
    "    y_test = y_smote[test]\n",
    "    \n",
    "#     scores.append(clf.predict_proba(X_smote[test]))\n",
    "    scores_id.append(test)\n",
    "    scores.append(clf.predict_proba(X_smote[test]))\n",
    "\n",
    "# save prediction score\n",
    "scores_id = np.concatenate(scores_id, axis=0) \n",
    "scores = np.concatenate(scores, axis=0) \n",
    "map_ids = []\n",
    "for i in range(len(donor_ids)):\n",
    "    map_ids.append(np.where(scores_id==i)[0][0])\n",
    "map_scores = scores[map_ids]\n",
    "y_predict = np.argmax(map_scores, axis=1) \n",
    "    \n",
    "accuracy_rf = accuracy_score(y, y_predict)\n",
    "confusion_mat_rf = confusion_matrix(y, y_predict)\n",
    "f1_rf = f1_score(y, y_predict)    \n",
    "auc_rf = roc_auc_score(y, y_predict)\n",
    "fpr_rf,tpr_rf,_ = roc_curve(y, y_predict)\n",
    "\n",
    "\n",
    "# clf.fit(X_smote, y_smote)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print('y_true', y_test)\n",
    "# print('y_predict', y_pred)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Prediction accuray:', accuracy_rf)\n",
    "\n",
    "# confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('confusion_mat:\\n', confusion_mat_rf)\n",
    "\n",
    "# f1_rf, auc_rf = f1_score(y_test, y_pred), roc_auc_score(y_test,y_pred)\n",
    "print('F1=%.3f Auc=%.3f' % (f1_rf, auc_rf))\n",
    "# fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred)\n",
    "pyplot.plot(fpr_rf, tpr_rf, marker='.', label='Random Forest')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "df_dt = pd.DataFrame(map_scores, index=donor_ids,  columns=['class 0', 'Class 1'])\n",
    "\n",
    "df_dt.to_excel(writer, 'Random Forest')\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Feedforward Neural Networks (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clf = MLPClassifier(random_state=1, solver='adam', activation='relu', hidden_layer_sizes=(140,),\n",
    "                    learning_rate_init=1e-2, learning_rate='adaptive', tol=1e-4, max_iter=2000)\n",
    "\n",
    "\n",
    "accs = []\n",
    "confusion_mats = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "scores = []\n",
    "scores_id=[]\n",
    "for i, (train, test) in enumerate(cv.split(X_smote, y_smote)):\n",
    "    clf.fit(X_smote[train], y_smote[train])\n",
    "    y_pred = clf.predict(X_smote[test])\n",
    "    y_test = y_smote[test]\n",
    "    \n",
    "#     scores.append(clf.predict_proba(X_smote[test]))\n",
    "    scores_id.append(test)\n",
    "    scores.append(clf.predict_proba(X_smote[test]))\n",
    "\n",
    "\n",
    "# save prediction score\n",
    "scores_id = np.concatenate(scores_id, axis=0) \n",
    "scores = np.concatenate(scores, axis=0) \n",
    "map_ids = []\n",
    "for i in range(len(donor_ids)):\n",
    "    map_ids.append(np.where(scores_id==i)[0][0])\n",
    "map_scores = scores[map_ids]\n",
    "y_predict = np.argmax(map_scores, axis=1) \n",
    "    \n",
    "accuracy_mlp = accuracy_score(y, y_predict)\n",
    "confusion_mat_mlp = confusion_matrix(y, y_predict)\n",
    "f1_mlp = f1_score(y, y_predict)    \n",
    "auc_mlp = roc_auc_score(y, y_predict)\n",
    "fpr_mlp,tpr_mlp,_ = roc_curve(y, y_predict)\n",
    "\n",
    "\n",
    "\n",
    "# clf.fit(X_smote, y_smote)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print('y_true', y_test)\n",
    "# print('y_predict', y_pred)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Prediction accuray:', accuracy_mlp)\n",
    "\n",
    "# confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('confusion_mat:\\n', confusion_mat_mlp)\n",
    "\n",
    "# clf.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# f1_mlp, auc_mlp = f1_score(y_test, y_pred), roc_auc_score(y_test,y_pred)\n",
    "print('F1=%.3f Auc=%.3f' % (f1_mlp, auc_mlp))\n",
    "# fpr_mlp, tpr_mlp, _ = roc_curve(y_test, y_pred)\n",
    "pyplot.plot(fpr_mlp, tpr_mlp, marker='.', label='Feedforward Neural Networks')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# # save prediction score\n",
    "# scores_id = np.concatenate(scores_id, axis=0) \n",
    "# scores = np.concatenate(scores, axis=0) \n",
    "# map_ids = []\n",
    "# for i in range(len(donor_ids)):\n",
    "#     map_ids.append(np.where(scores_id==i)[0][0])\n",
    "# map_scores = scores[map_ids]\n",
    "\n",
    "df_dt = pd.DataFrame(map_scores, index=donor_ids,  columns=['class 0', 'Class 1'])\n",
    "\n",
    "df_dt.to_excel(writer, 'Feedforward Neural Networks')\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto', kernel='rbf', C=2, probability=True))\n",
    "\n",
    "accs = []\n",
    "confusion_mats = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "scores = []\n",
    "scores_id=[]\n",
    "for i, (train, test) in enumerate(cv.split(X_smote, y_smote)):\n",
    "    clf.fit(X_smote[train], y_smote[train])\n",
    "    y_pred = clf.predict(X_smote[test])\n",
    "    y_test = y_smote[test]\n",
    "\n",
    "    scores_id.append(test)\n",
    "    scores.append(clf.predict_proba(X_smote[test]))\n",
    "\n",
    "\n",
    "# save prediction score\n",
    "scores_id = np.concatenate(scores_id, axis=0) \n",
    "scores = np.concatenate(scores, axis=0) \n",
    "map_ids = []\n",
    "for i in range(len(donor_ids)):\n",
    "    map_ids.append(np.where(scores_id==i)[0][0])\n",
    "map_scores = scores[map_ids]\n",
    "y_predict = np.argmax(map_scores, axis=1) \n",
    "    \n",
    "accuracy_svm = accuracy_score(y, y_predict)\n",
    "confusion_mat_svm = confusion_matrix(y, y_predict)\n",
    "f1_svm = f1_score(y, y_predict)    \n",
    "auc_svm = roc_auc_score(y, y_predict)\n",
    "fpr_svm,tpr_svm,_ = roc_curve(y, y_predict)\n",
    "\n",
    "\n",
    "\n",
    "# clf.fit(X_smote, y_smote)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print('y_true', y_test)\n",
    "# print('y_predict', y_pred)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Prediction accuray:', accuracy_svm)\n",
    "\n",
    "# confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('confusion_mat:\\n', confusion_mat_svm)\n",
    "\n",
    "\n",
    "# f1_svm, auc_svm = f1_score(y_test, y_pred), roc_auc_score(y_test,y_pred)\n",
    "print('F1=%.3f Auc=%.3f' % (f1_svm, auc_svm))\n",
    "# fpr_svm, tpr_svm, _ = roc_curve(y_test, y_pred)\n",
    "pyplot.plot(fpr_svm, tpr_svm, marker='.', label='Support Vector Machine')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# # save prediction score\n",
    "# scores_id = np.concatenate(scores_id, axis=0) \n",
    "# scores = np.concatenate(scores, axis=0) \n",
    "# map_ids = []\n",
    "# for i in range(len(donor_ids)):\n",
    "#     map_ids.append(np.where(scores_id==i)[0][0])\n",
    "# map_scores = scores[map_ids]\n",
    "\n",
    "df_dt = pd.DataFrame(map_scores, index=donor_ids,  columns=['class 0', 'Class 1'])\n",
    "\n",
    "df_dt.to_excel(writer, 'Support Vector Machine')\n",
    "writer.save()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# clf_base =DecisionTreeClassifier(random_state=0, max_depth=16, criterion='entropy', min_samples_split=4)\n",
    "clf_base = RandomForestClassifier(max_depth=18, random_state=0)\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=220, random_state=0, learning_rate=1e-3, base_estimator=clf_base)\n",
    "\n",
    "accs = []\n",
    "confusion_mats = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "scores = []\n",
    "scores_id=[]\n",
    "for i, (train, test) in enumerate(cv.split(X_smote, y_smote)):\n",
    "    clf.fit(X_smote[train], y_smote[train])\n",
    "    y_pred = clf.predict(X_smote[test])\n",
    "    y_test = y_smote[test]\n",
    "    \n",
    "#     scores.append(clf.predict_proba(X_smote[test]))\n",
    "    scores_id.append(test)\n",
    "    scores.append(clf.predict_proba(X_smote[test]))\n",
    "    \n",
    "# save prediction score\n",
    "scores_id = np.concatenate(scores_id, axis=0) \n",
    "scores = np.concatenate(scores, axis=0) \n",
    "map_ids = []\n",
    "for i in range(len(donor_ids)):\n",
    "    map_ids.append(np.where(scores_id==i)[0][0])\n",
    "map_scores = scores[map_ids]\n",
    "y_predict = np.argmax(map_scores, axis=1) \n",
    "    \n",
    "accuracy_adaboost = accuracy_score(y, y_predict)\n",
    "confusion_mat_adaboost = confusion_matrix(y, y_predict)\n",
    "f1_adaboost = f1_score(y, y_predict)    \n",
    "auc_adaboost = roc_auc_score(y, y_predict)\n",
    "fpr_adaboost,tpr_adaboost,_ = roc_curve(y, y_predict)\n",
    "\n",
    "\n",
    "# clf.fit(X_smote, y_smote)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print('y_true', y_test)\n",
    "# print('y_predict', y_pred)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Prediction accuray:', accuracy_adaboost)\n",
    "\n",
    "# confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('confusion_mat:\\n', confusion_mat_adaboost)\n",
    "\n",
    "# clf.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# f1_adaboost, auc_adaboost = f1_score(y_test, y_pred), roc_auc_score(y_test,y_pred)\n",
    "print('F1=%.3f Auc=%.3f' % (f1_adaboost, auc_adaboost))\n",
    "# fpr_adaboost, tpr_adaboost, _ = roc_curve(y_test, y_pred)\n",
    "pyplot.plot(fpr_adaboost, tpr_adaboost, marker='.', label='AdaBoost')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "# # save prediction score\n",
    "# scores_id = np.concatenate(scores_id, axis=0) \n",
    "# scores = np.concatenate(scores, axis=0) \n",
    "# map_ids = []\n",
    "# for i in range(len(donor_ids)):\n",
    "#     map_ids.append(np.where(scores_id==i)[0][0])\n",
    "# map_scores = scores[map_ids]\n",
    "\n",
    "df_dt = pd.DataFrame(map_scores, index=donor_ids,  columns=['class 0', 'Class 1'])\n",
    "\n",
    "df_dt.to_excel(writer, 'AdaBoost')\n",
    "writer.save()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.7 GradientBoosting \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=200, learning_rate=1e-3,\n",
    "     max_depth=1, random_state=0, loss='exponential')\n",
    "\n",
    "\n",
    "accs = []\n",
    "confusion_mats = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "scores = []\n",
    "scores_id=[]\n",
    "for i, (train, test) in enumerate(cv.split(X_smote, y_smote)):\n",
    "    clf.fit(X_smote[train], y_smote[train])\n",
    "    y_pred = clf.predict(X_smote[test])\n",
    "    y_test = y_smote[test]\n",
    "    \n",
    "#     scores.append(clf.predict_proba(X_smote[test]))\n",
    "    scores_id.append(test)\n",
    "    scores.append(clf.predict_proba(X_smote[test]))\n",
    "\n",
    "\n",
    "# save prediction score\n",
    "scores_id = np.concatenate(scores_id, axis=0) \n",
    "scores = np.concatenate(scores, axis=0) \n",
    "map_ids = []\n",
    "for i in range(len(donor_ids)):\n",
    "    map_ids.append(np.where(scores_id==i)[0][0])\n",
    "map_scores = scores[map_ids]\n",
    "y_predict = np.argmax(map_scores, axis=1) \n",
    "    \n",
    "accuracy_gradientboosting = accuracy_score(y, y_predict)\n",
    "confusion_mat_gradientboosting = confusion_matrix(y, y_predict)\n",
    "f1_gradientboosting = f1_score(y, y_predict)    \n",
    "auc_gradientboosting = roc_auc_score(y, y_predict)\n",
    "fpr_gradientboosting,tpr_gradientboosting,_ = roc_curve(y, y_predict)\n",
    "\n",
    "# clf.fit(X_smote, y_smote)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print('y_true', y_test)\n",
    "# print('y_predict', y_pred)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Prediction accuray:', accuracy_gradientboosting)\n",
    "\n",
    "# confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('confusion_mat:\\n', confusion_mat_gradientboosting)\n",
    "\n",
    "# f1_gradientboosting, auc_gradientboosting = f1_score(y_test, y_pred), roc_auc_score(y_test,y_pred)\n",
    "print('F1=%.3f Auc=%.3f' % (f1_gradientboosting, auc_gradientboosting))\n",
    "# fpr_gradientboosting, tpr_gradientboosting, _ = roc_curve(y_test, y_pred)\n",
    "pyplot.plot(fpr_gradientboosting, tpr_gradientboosting, marker='.', label='GradientBoosting')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "# # save prediction score\n",
    "# scores_id = np.concatenate(scores_id, axis=0) \n",
    "# scores = np.concatenate(scores, axis=0) \n",
    "# map_ids = []\n",
    "# for i in range(len(donor_ids)):\n",
    "#     map_ids.append(np.where(scores_id==i)[0][0])\n",
    "# map_scores = scores[map_ids]\n",
    "\n",
    "df_dt = pd.DataFrame(map_scores, index=donor_ids,  columns=['class 0', 'Class 1'])\n",
    "\n",
    "df_dt.to_excel(writer, 'GradientBoosting')\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. PLot ROC Curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(fpr_dt, tpr_dt, marker='.', linestyle='--', label='Decision Tree')\n",
    "pyplot.plot(fpr_lr, tpr_lr, marker='.', label='Linear Regression')\n",
    "pyplot.plot(fpr_rf, tpr_rf, marker='.', label='Random Forest')\n",
    "pyplot.plot(fpr_svm, tpr_svm, marker='.', label='Support Vector Machine')\n",
    "pyplot.plot(fpr_mlp, tpr_mlp, marker='.', label='Feedforward Neural Networks')\n",
    "pyplot.plot(fpr_adaboost, tpr_adaboost, linestyle=':', marker='.', label='AdaBoost')\n",
    "# pyplot.plot(fpr_rusboost, tpr_rusboost, marker='.', label='RUSBoost')\n",
    "# pyplot.plot(fpr_smoteboost, tpr_smoteboost, marker='.', label='SMOTEBoost')\n",
    "pyplot.plot(fpr_gradientboosting, tpr_gradientboosting, marker='.', label='GradientBoosting')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate',fontsize=12)\n",
    "pyplot.ylabel('True Positive Rate', fontsize=12)\n",
    "# show the legend\n",
    "pyplot.legend(loc=0,)\n",
    "\n",
    "print('1. Decision Tree: Acc=%.3f, F1=%.3f, Auc=%.3f' % (accuracy_dt, f1_dt, auc_dt))\n",
    "print('2. Linear Regression: Acc=%.3f, F1=%.3f, Auc=%.3f' % (accuracy_lr, f1_lr, auc_lr))\n",
    "print('3. Random Forest: Acc=%.3f, F1=%.3f, Auc=%.3f' % (accuracy_rf, f1_rf, auc_rf))\n",
    "print('4. Support Vector Machine: Acc=%.3f, F1=%.3f, Auc=%.3f' % (accuracy_svm, f1_svm, auc_svm))\n",
    "print('5. Feedforward Neural Networks: Acc=%.3f, F1=%.3f, Auc=%.3f' % (accuracy_mlp, f1_mlp, auc_mlp))\n",
    "print('6. AdaBoost: Acc=%.3f, F1=%.3f, Auc=%.3f' % (accuracy_adaboost, f1_adaboost, auc_adaboost))\n",
    "# print('7. RUBBoost: F1=%.3f, Auc=%.3f' % (f1_rusboost, auc_rusboost))\n",
    "# print('8. SMOTEBoost: F1=%.3f, Auc=%.3f' % (f1_smoteboost, auc_smoteboost))\n",
    "print('9. GradientBoosting: Acc=%.3f, F1=%.3f, Auc=%.3f' % (accuracy_gradientboosting, f1_gradientboosting, auc_gradientboosting))\n",
    "\n",
    "plt.legend(fontsize=11,handletextpad=0.2)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. PLot Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "y=['Class 0','Class 1']\n",
    "# Generate a large random dataset\n",
    "fig1=plt.figure(figsize=(3, 3))\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.heatmap(confusion_mat_dt, vmin=0, vmax=550, annot=True, square=True, xticklabels=y, yticklabels=y, cmap='RdPu', fmt=\"d\",cbar=False)\n",
    "ax.xaxis.tick_top()\n",
    "ax.yaxis.tick_left()\n",
    "ax.set_xticklabels(y, fontsize=14)\n",
    "ax.set_yticklabels(y, fontsize=14)\n",
    "plt.xlabel('Decision Tree', fontsize=14, labelpad=11)\n",
    "plt.title(\"Predicted\", fontsize=14)\n",
    "pyplot.ylabel('Actual', fontsize=14)\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=0) \n",
    "plt.show()\n",
    "\n",
    "\n",
    "############################\n",
    "y=['Class 0','Class 1']\n",
    "# Generate a large random dataset\n",
    "fig2=plt.figure(figsize=(3, 3))\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.heatmap(confusion_mat_lr,vmin=0, vmax=550, annot=True, square=True, xticklabels=y, yticklabels=y, cmap='RdPu', fmt=\"d\",cbar=False)\n",
    "ax.xaxis.tick_top()\n",
    "ax.yaxis.tick_left()\n",
    "ax.set_xticklabels(y, fontsize=14)\n",
    "ax.set_yticklabels(y, fontsize=14)\n",
    "plt.title(\"Predicted\", fontsize=14)\n",
    "pyplot.ylabel('Actual', fontsize=14)\n",
    "plt.xlabel('Linear Regression', fontsize=14, labelpad=11)\n",
    "\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=0) \n",
    "plt.show()\n",
    "\n",
    "############################\n",
    "y=['Class 0','Class 1']\n",
    "# Generate a large random dataset\n",
    "fig3 = plt.figure(figsize=(3, 3))\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.heatmap(confusion_mat_rf,vmin=0, vmax=550, annot=True, square=True, xticklabels=y, yticklabels=y, cmap='RdPu', fmt=\"d\",cbar=False)\n",
    "ax.xaxis.tick_top()\n",
    "ax.yaxis.tick_left()\n",
    "ax.set_xticklabels(y, fontsize=14)\n",
    "ax.set_yticklabels(y, fontsize=14)\n",
    "plt.title(\"Predicted\", fontsize=14)\n",
    "pyplot.ylabel('Actual', fontsize=14)\n",
    "plt.xlabel('Random Forest', fontsize=14, labelpad=11)\n",
    "\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=0) \n",
    "plt.show()\n",
    "\n",
    "\n",
    "#####################\n",
    "\n",
    "fig4 = plt.figure(figsize=(3, 3))\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.heatmap(confusion_mat_svm,vmin=0, vmax=550, annot=True, square=True, xticklabels=y, yticklabels=y, cmap='RdPu', fmt=\"d\",cbar=False)\n",
    "ax.xaxis.tick_top()\n",
    "ax.yaxis.tick_left()\n",
    "ax.set_xticklabels(y, fontsize=14)\n",
    "ax.set_yticklabels(y, fontsize=14)\n",
    "plt.title(\"Predicted\", fontsize=14)\n",
    "pyplot.ylabel('Actual', fontsize=14)\n",
    "plt.xlabel('Support Vector Machine', fontsize=14, labelpad=11)\n",
    "\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=0) \n",
    "plt.show()\n",
    "\n",
    "\n",
    "#####################\n",
    "\n",
    "fig5 = plt.figure(figsize=(3, 3))\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.heatmap(confusion_mat_mlp,vmin=0, vmax=550, annot=True, square=True, xticklabels=y, yticklabels=y, cmap='RdPu', fmt=\"d\",cbar=False)\n",
    "ax.xaxis.tick_top()\n",
    "ax.yaxis.tick_left()\n",
    "ax.set_xticklabels(y, fontsize=14)\n",
    "ax.set_yticklabels(y, fontsize=14)\n",
    "plt.title(\"Predicted\", fontsize=14)\n",
    "pyplot.ylabel('Actual', fontsize=14)\n",
    "plt.xlabel('Feedforward Neural Networks', fontsize=14, labelpad=11)\n",
    "\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=0) \n",
    "plt.show()\n",
    "\n",
    "\n",
    "#####################\n",
    "\n",
    "fig6 = plt.figure(figsize=(3, 3))\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.heatmap(confusion_mat_adaboost,vmin=0, vmax=550, annot=True, square=True, xticklabels=y, yticklabels=y, cmap='RdPu', fmt=\"d\",cbar=False)\n",
    "ax.xaxis.tick_top()\n",
    "ax.yaxis.tick_left()\n",
    "ax.set_xticklabels(y, fontsize=14)\n",
    "ax.set_yticklabels(y, fontsize=14)\n",
    "plt.title(\"Predicted\", fontsize=14)\n",
    "pyplot.ylabel('Actual', fontsize=14)\n",
    "plt.xlabel('AdaBoost', fontsize=14, labelpad=11)\n",
    "\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=0) \n",
    "plt.show()\n",
    "\n",
    "\n",
    "#####################\n",
    "\n",
    "fig7 = plt.figure(figsize=(3, 3))\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.heatmap(confusion_mat_gradientboosting,vmin=0, vmax=550, annot=True, square=True, xticklabels=y, yticklabels=y, cmap='RdPu', fmt=\"d\",cbar=False)\n",
    "ax.xaxis.tick_top()\n",
    "ax.yaxis.tick_left()\n",
    "ax.set_xticklabels(y, fontsize=14)\n",
    "ax.set_yticklabels(y, fontsize=14)\n",
    "plt.title(\"Predicted\", fontsize=14)\n",
    "pyplot.ylabel('Actual', fontsize=14)\n",
    "plt.xlabel('GradientBoosting', fontsize=14, labelpad=11)\n",
    "\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=0) \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Plot Acc, F1 and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = [accuracy_dt, f1_dt, auc_dt]\n",
    "LR = [accuracy_lr, f1_lr, auc_lr]\n",
    "RF = [accuracy_rf, f1_rf, auc_rf]\n",
    "SVM = [accuracy_svm, f1_svm, auc_svm]\n",
    "FNN = [accuracy_mlp, f1_mlp, auc_mlp]\n",
    "adaboost = [accuracy_adaboost, f1_adaboost, auc_adaboost]\n",
    "gradboost = [accuracy_gradientboosting, f1_gradientboosting, auc_gradientboosting]\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(3)\n",
    "bar_width = 0.1\n",
    "opacity = 0.8\n",
    "plt.figure()\n",
    " \n",
    "rects1 = plt.bar(index, DT, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='#B8860B',\n",
    "                 label='Decision Tree')\n",
    "rects2 = plt.bar(index + bar_width, LR, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='#FF7F00',\n",
    "                 label='Linear Regression')\n",
    "rects3 = plt.bar(index + 2*bar_width, RF, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='green',\n",
    "                 label='Random Forest') \n",
    "rects4 = plt.bar(index + 3*bar_width, SVM, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='indigo',\n",
    "                 label='SVM')\n",
    "rects5 = plt.bar(index + 4*bar_width, FNN, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='#1C86EE',\n",
    "                 label='FNN')\n",
    "rects6 = plt.bar(index + 5*bar_width, adaboost, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='#838B8B',\n",
    "                 label='AdaBoost')\n",
    "rects7 = plt.bar(index + 6*bar_width, gradboost, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='#DEB887',\n",
    "                 label='GradientBoosting')\n",
    " \n",
    "plt.xlabel('Comparisons on Different Metrics', fontsize=13)\n",
    "plt.ylabel('Performance', fontsize=13)\n",
    "plt.xticks(index + 2.5*bar_width, ['Accuracy','F1','AUC'], fontsize=13)\n",
    " \n",
    "plt.legend(fontsize=11,handletextpad=0.2,loc=1, bbox_to_anchor=(1, 0.6))\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
